{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pooled_GRUFastText.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gr8nishan/MLWork/blob/master/Pooled_GRUFastText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-m36De3B_xh",
        "colab_type": "text"
      },
      "source": [
        "Downloading data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNFEQhztr7tD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "user = \"gr8nishan\"\n",
        "key = \"31304a62cb2b1214c67a14887ba0f506\"\n",
        "\n",
        "if '.kaggle' not in os.listdir('/root'):\n",
        "    !mkdir ~/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 666 /root/.kaggle/kaggle.json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6SyWD3Vr-8e",
        "colab_type": "code",
        "outputId": "ecac7d80-3f97-4398-8f82-41b1fc095644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 46.7MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 73% 17.0M/23.4M [00:01<00:00, 14.2MB/s]\n",
            "100% 23.4M/23.4M [00:01<00:00, 16.7MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 65% 17.0M/26.3M [00:01<00:00, 15.4MB/s]\n",
            "100% 26.3M/26.3M [00:01<00:00, 19.5MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 48.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7E37H-cCFis",
        "colab_type": "text"
      },
      "source": [
        "Unzipping training and testing file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gz391dstDuP",
        "colab_type": "code",
        "outputId": "ced319ba-b659-4f57-b83e-3a24e8114c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!unzip /content/train.csv.zip\n",
        "!unzip /content/test.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  /content/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bca8nEFDCJUs",
        "colab_type": "text"
      },
      "source": [
        "Downloading fast text vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtBKsPeBLB1T",
        "colab_type": "code",
        "outputId": "a75096da-e2dc-44c3-c5c0-2bc8d3fa6e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-25 11:47:25--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  11.5MB/s    in 2m 7s   \n",
            "\n",
            "2019-11-25 11:49:33 (11.4 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JSyx2zLCM_R",
        "colab_type": "text"
      },
      "source": [
        "Unzipping fast text vecotrs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3A-qORKLYSn",
        "colab_type": "code",
        "outputId": "b5b75e5f-4c3a-4b5c-ce48-a50089ac1cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip crawl-300d-2M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHJddK6Huj8d",
        "colab_type": "code",
        "outputId": "fd829374-fbe4-433d-e524-f38580fa0954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip /content/sample_submission.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVCEOiZmCP7C",
        "colab_type": "text"
      },
      "source": [
        "importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmiwR2yiKGUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
        "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '4'\n",
        "\n",
        "\n",
        "EMBEDDING_FILE = '/content/crawl-300d-2M.vec'\n",
        "\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "submission = pd.read_csv('/content/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Y_l2RKvJmL",
        "colab_type": "code",
        "outputId": "f26ea369-a09a-4ab8-9c25-92b3284b3edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohaxAR1O03-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11n8fXovCVWB",
        "colab_type": "text"
      },
      "source": [
        "Converting to a binary classification\n",
        "If all the classes are 0 then the new class **finaltoxicity** will be 0 else if any of the class is 1 then **finaltoxicity** will be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg86Sxme1p7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[(df.toxic==0) &(df.severe_toxic==0) & (df.obscene==0) & (df.threat==0) & (df.insult==0) & (df.identity_hate==0), 'finaltoxicity'] = 0\n",
        "df.loc[(df.toxic==1) | (df.severe_toxic==1) | (df.obscene==1) | (df.threat==1) | (df.insult==1) | (df.identity_hate==1), 'finaltoxicity'] = 1\n",
        "#df.loc[df.set_of_numbers > 4, 'equal_or_lower_than_4?'] = 'False'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK45Qzn-17Ul",
        "colab_type": "code",
        "outputId": "6de3b175-1db8-4a00-9616-a7eec3565c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>finaltoxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... finaltoxicity\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             1\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns5YkKBpCrQE",
        "colab_type": "text"
      },
      "source": [
        "this will give how many rows contains 1 and how many rows contains 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe1HMlwt23R9",
        "colab_type": "code",
        "outputId": "e745a19e-768a-4865-e9d8-5a18f2dfd7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(df['finaltoxicity'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    144277\n",
            "1     15294\n",
            "Name: toxic, dtype: int64 0    143346\n",
            "1     16225\n",
            "Name: finaltoxicity, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pr2otG4fn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urb4Gp_2C0JE",
        "colab_type": "text"
      },
      "source": [
        "this will rempve punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXeQ8x-k4UMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "puncts = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~.'\n",
        "def remove_punctuation_3(text):\n",
        "  return text.translate(str.maketrans('', '', puncts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWiIvcGZC3VH",
        "colab_type": "text"
      },
      "source": [
        "this will remove all contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_5NGR-J4Xwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aiXM2BLC7II",
        "colab_type": "text"
      },
      "source": [
        "preprocessing for the dataset, replacing few words based on dataset, spelling correction etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUAIrExk5LJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import re\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "\n",
        "class BaseTokenizer(object):\n",
        "    def process_text(self, text):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def process(self, texts):\n",
        "        for text in texts:\n",
        "            yield self.process_text(text)\n",
        "\n",
        "\n",
        "RE_PATTERNS = {\n",
        "    ' american ':\n",
        "        [\n",
        "            'amerikan'\n",
        "        ],\n",
        "\n",
        "    ' adolf ':\n",
        "        [\n",
        "            'adolf'\n",
        "        ],\n",
        "\n",
        "\n",
        "    ' hitler ':\n",
        "        [\n",
        "            'hitler'\n",
        "        ],\n",
        "\n",
        "    ' fuck':\n",
        "        [\n",
        "            '(f)(u|[^a-z0-9 ])(c|[^a-z0-9 ])(k|[^a-z0-9 ])([^ ])*',\n",
        "            '(f)([^a-z]*)(u)([^a-z]*)(c)([^a-z]*)(k)',\n",
        "            ' f[!@#\\$%\\^\\&\\*]*u[!@#\\$%\\^&\\*]*k', 'f u u c',\n",
        "            '(f)(c|[^a-z ])(u|[^a-z ])(k)', r'f\\*',\n",
        "            'feck ', ' fux ', 'f\\*\\*', \n",
        "            'f\\-ing', 'f\\.u\\.', 'f###', ' fu ', 'f@ck', 'f u c k', 'f uck', 'f ck'\n",
        "        ],\n",
        "\n",
        "    ' ass ':\n",
        "        [\n",
        "            '[^a-z]ass ', '[^a-z]azz ', 'arrse', ' arse ', '@\\$\\$'\n",
        "                                                           '[^a-z]anus', ' a\\*s\\*s', '[^a-z]ass[^a-z ]',\n",
        "            'a[@#\\$%\\^&\\*][@#\\$%\\^&\\*]', '[^a-z]anal ', 'a s s'\n",
        "        ],\n",
        "\n",
        "    ' ass hole ':\n",
        "        [\n",
        "            ' a[s|z]*wipe', 'a[s|z]*[w]*h[o|0]+[l]*e', '@\\$\\$hole'\n",
        "        ],\n",
        "\n",
        "    ' bitch ':\n",
        "        [\n",
        "            'b[w]*i[t]*ch', 'b!tch',\n",
        "            'bi\\+ch', 'b!\\+ch', '(b)([^a-z]*)(i)([^a-z]*)(t)([^a-z]*)(c)([^a-z]*)(h)',\n",
        "            'biatch', 'bi\\*\\*h', 'bytch', 'b i t c h'\n",
        "        ],\n",
        "\n",
        "    ' bastard ':\n",
        "        [\n",
        "            'ba[s|z]+t[e|a]+rd'\n",
        "        ],\n",
        "\n",
        "    ' trans gender':\n",
        "        [\n",
        "            'transgender'\n",
        "        ],\n",
        "\n",
        "    ' gay ':\n",
        "        [\n",
        "            'gay'\n",
        "        ],\n",
        "\n",
        "    ' cock ':\n",
        "        [\n",
        "            '[^a-z]cock', 'c0ck', '[^a-z]cok ', 'c0k', '[^a-z]cok[^aeiou]', ' cawk',\n",
        "            '(c)([^a-z ])(o)([^a-z ]*)(c)([^a-z ]*)(k)', 'c o c k'\n",
        "        ],\n",
        "\n",
        "    ' dick ':\n",
        "        [\n",
        "            ' dick[^aeiou]', 'deek', 'd i c k'\n",
        "        ],\n",
        "\n",
        "    ' suck ':\n",
        "        [\n",
        "            'sucker', '(s)([^a-z ]*)(u)([^a-z ]*)(c)([^a-z ]*)(k)', 'sucks', '5uck', 's u c k'\n",
        "        ],\n",
        "\n",
        "    ' cunt ':\n",
        "        [\n",
        "            'cunt', 'c u n t'\n",
        "        ],\n",
        "\n",
        "    ' bull shit ':\n",
        "        [\n",
        "            'bullsh\\*t', 'bull\\$hit'\n",
        "        ],\n",
        "\n",
        "    ' homo sex ual':\n",
        "        [\n",
        "            'homosexual'\n",
        "        ],\n",
        "\n",
        "    ' jerk ':\n",
        "        [\n",
        "            'jerk'\n",
        "        ],\n",
        "\n",
        "    ' idiot ':\n",
        "        [\n",
        "            'i[d]+io[t]+', '(i)([^a-z ]*)(d)([^a-z ]*)(i)([^a-z ]*)(o)([^a-z ]*)(t)', 'idiots'\n",
        "                                                                                      'i d i o t'\n",
        "        ],\n",
        "\n",
        "    ' dumb ':\n",
        "        [\n",
        "            '(d)([^a-z ]*)(u)([^a-z ]*)(m)([^a-z ]*)(b)'\n",
        "        ],\n",
        "\n",
        "    ' shit ':\n",
        "        [\n",
        "            'shitty', '(s)([^a-z ]*)(h)([^a-z ]*)(i)([^a-z ]*)(t)', 'shite', '\\$hit', 's h i t'\n",
        "        ],\n",
        "\n",
        "    ' shit hole ':\n",
        "        [\n",
        "            'shythole'\n",
        "        ],\n",
        "\n",
        "    ' retard ':\n",
        "        [\n",
        "            'returd', 'retad', 'retard', 'wiktard', 'wikitud'\n",
        "        ],\n",
        "\n",
        "    ' rape ':\n",
        "        [\n",
        "            ' raped'\n",
        "        ],\n",
        "\n",
        "    ' dumb ass':\n",
        "        [\n",
        "            'dumbass', 'dubass'\n",
        "        ],\n",
        "\n",
        "    ' ass head':\n",
        "        [\n",
        "            'butthead'\n",
        "        ],\n",
        "\n",
        "    ' sex ':\n",
        "        [\n",
        "            'sexy', 's3x', 'sexuality'\n",
        "        ],\n",
        "\n",
        "\n",
        "    ' nigger ':\n",
        "        [\n",
        "            'nigger', 'ni[g]+a', ' nigr ', 'negrito', 'niguh', 'n3gr', 'n i g g e r'\n",
        "        ],\n",
        "\n",
        "    ' shut the fuck up':\n",
        "        [\n",
        "            'stfu'\n",
        "        ],\n",
        "\n",
        "    ' pussy ':\n",
        "        [\n",
        "            'pussy[^c]', 'pusy', 'pussi[^l]', 'pusses'\n",
        "        ],\n",
        "\n",
        "    ' faggot ':\n",
        "        [\n",
        "            'faggot', ' fa[g]+[s]*[^a-z ]', 'fagot', 'f a g g o t', 'faggit',\n",
        "            '(f)([^a-z ]*)(a)([^a-z ]*)([g]+)([^a-z ]*)(o)([^a-z ]*)(t)', 'fau[g]+ot', 'fae[g]+ot',\n",
        "        ],\n",
        "\n",
        "    ' mother fucker':\n",
        "        [\n",
        "            ' motha ', ' motha f', ' mother f', 'motherucker',\n",
        "        ],\n",
        "\n",
        "    ' whore ':\n",
        "        [\n",
        "            'wh\\*\\*\\*', 'w h o r e'\n",
        "        ],\n",
        "}\n",
        "\n",
        "\n",
        "class PatternTokenizer(BaseTokenizer):\n",
        "    def __init__(self, lower=True, initial_filters=r\"[^a-z0-9!@#\\$%\\^\\&\\*_\\-,\\.' ]\", patterns=RE_PATTERNS,\n",
        "                 remove_repetitions=True):\n",
        "        self.lower = lower\n",
        "        self.patterns = patterns\n",
        "        self.initial_filters = initial_filters\n",
        "        self.remove_repetitions = remove_repetitions\n",
        "\n",
        "    def process_text(self, text):\n",
        "        x = self._preprocess(text)\n",
        "        for target, patterns in self.patterns.items():\n",
        "            for pat in patterns:\n",
        "                x = re.sub(pat, target, x)\n",
        "        x = re.sub(r\"[^a-z' ]\", ' ', x)\n",
        "        return x.split()\n",
        "\n",
        "    def process_ds(self, ds):\n",
        "        ### ds = Data series\n",
        "\n",
        "        # lower\n",
        "        ds = copy.deepcopy(ds)\n",
        "        if self.lower:\n",
        "            ds = ds.str.lower()\n",
        "        # remove special chars\n",
        "        if self.initial_filters is not None:\n",
        "            ds = ds.str.replace(self.initial_filters, ' ')\n",
        "        # fuuuuck => fuck\n",
        "        if self.remove_repetitions:\n",
        "            pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL) \n",
        "            ds = ds.str.replace(pattern, r\"\\1\")\n",
        "\n",
        "        for target, patterns in self.patterns.items():\n",
        "            for pat in patterns:\n",
        "                ds = ds.str.replace(pat, target)\n",
        "\n",
        "        ds = ds.str.replace(r\"[^a-z' ]\", ' ')\n",
        "\n",
        "        return ds.str.split()\n",
        "\n",
        "    def _preprocess(self, text):\n",
        "        # lower\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "\n",
        "        # remove special chars\n",
        "        if self.initial_filters is not None:\n",
        "            text = re.sub(self.initial_filters, ' ', text)\n",
        "\n",
        "        # fuuuuck => fuck\n",
        "        if self.remove_repetitions:\n",
        "            pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
        "            text = pattern.sub(r\"\\1\", text)\n",
        "        return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKrYCxsDDNCy",
        "colab_type": "text"
      },
      "source": [
        "intiializing constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbaPgyWTuJp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 30000\n",
        "maxlen = 100\n",
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IvxK0-w5wtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN=\"comment_text\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyEweLE7DPOW",
        "colab_type": "text"
      },
      "source": [
        "preprocessing training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7M6FTU8hPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = PatternTokenizer()\n",
        "df[DATA_COLUMN] = df[DATA_COLUMN].map(lambda x: replace_contractions(x))\n",
        "df[DATA_COLUMN] = tokenizer.process_ds(df[DATA_COLUMN]).str.join(sep=\" \")\n",
        "df[DATA_COLUMN] = df[DATA_COLUMN].map(lambda x: remove_punctuation_3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYOjxea9DR6w",
        "colab_type": "text"
      },
      "source": [
        "preprocessing test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bheHuqnf9n8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[DATA_COLUMN] = test[DATA_COLUMN].map(lambda x: replace_contractions(x))\n",
        "test[DATA_COLUMN] = tokenizer.process_ds(test[DATA_COLUMN]).str.join(sep=\" \")\n",
        "test[DATA_COLUMN] = test[DATA_COLUMN].map(lambda x: remove_punctuation_3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V2Gjg0HDUvZ",
        "colab_type": "text"
      },
      "source": [
        "y_train,x_test and x_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wOSzaFw4_LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = df['finaltoxicity'].values\n",
        "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
        "X_train = df[\"comment_text\"].fillna(\"fillna\").values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6U94cgRDZG5",
        "colab_type": "text"
      },
      "source": [
        "intializing keras tokenizer-- this will create a vocabulary having max of 30000 words and assign a unique number to each word,\n",
        "converting train and test text into sequence of numbers and padding them \n",
        "max length for each sentence is 100 if the sentence is greater than 100 it will be truncated and if it is lesser than 100 it will be padded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAFS55RqL_jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gklk7-ENvv",
        "colab_type": "text"
      },
      "source": [
        "filling null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmD93JBrbd52",
        "colab_type": "code",
        "outputId": "f6fca994-e84c-48cc-f783-7b7caba20be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "X_train1 = train[\"comment_text\"].fillna(\"fillna\").values\n",
        "X_train1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['explanation why the edits made under my username hardcore metallica fan were reverted they were not vandalisms just closure on some gas after i voted at new york dolls fac and please do not remove the template from the talk page since i am retired now',\n",
              "       'daww he matches this background colour i am seemingly stuck with thanks talk january utc',\n",
              "       'hey man i am really not trying to edit war its just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info',\n",
              "       ...,\n",
              "       'spitzer umm theres no actual article for prostitution ring crunch captain',\n",
              "       'and it looks like it was actually you who put on the speedy to have the first version deleted now that i look at it',\n",
              "       'and i really do not think you understand i came here and my idea was bad right away what kind of community goes you have bad ideas go away instead of helping rewrite them'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9stuy-eEQk5",
        "colab_type": "text"
      },
      "source": [
        "creating pickle file for tokenizer so that it can be used while prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NlTJbYLA25A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv-Kw9uXEWyD",
        "colab_type": "text"
      },
      "source": [
        "creating an enmbedding vector using fast text and our text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFTC1sqtMB-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4_jFj8tEc59",
        "colab_type": "text"
      },
      "source": [
        "saving the embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s1BHMM986TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# np.save('/content/drive/My Drive/DataSet/toxic_comment/x_test.np',x_test)\n",
        "\n",
        "np.save('/content/embedding_matrix',embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXf-KnqKEfT6",
        "colab_type": "text"
      },
      "source": [
        "writing the rocauc evaluation class which will give roc and auc value after each epoch training is completed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S28scxZBOzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9zeBu_3Emr_",
        "colab_type": "text"
      },
      "source": [
        "creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevdM0l4BHQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    outp = Dense(2, activation=\"sigmoid\")(conc)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH-wlvFu7eD8",
        "colab_type": "code",
        "outputId": "cde5637b-58d7-4b4b-b178-b2fadef4b0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.0231    ,  0.017     ,  0.0157    , ...,  0.0744    ,\n",
              "        -0.1118    ,  0.0963    ],\n",
              "       [-0.0175    , -0.2189    ,  0.0353    , ..., -0.28459999,\n",
              "         0.0509    ,  0.0229    ],\n",
              "       ...,\n",
              "       [ 0.18269999, -0.2128    , -0.0233    , ..., -0.45300001,\n",
              "         0.12620001, -0.1129    ],\n",
              "       [-0.39930001, -0.454     ,  0.2484    , ..., -0.0574    ,\n",
              "        -0.3475    , -0.1999    ],\n",
              "       [-0.9497    , -0.0494    ,  0.1279    , ..., -0.0698    ,\n",
              "        -0.32429999,  0.08      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpL4kUI9EqeF",
        "colab_type": "text"
      },
      "source": [
        "converitng the label into one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-WiHYFFClcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train = y_train.reshape(-1,1)\n",
        "enc.fit(y_train)\n",
        "y = enc.transform(y_train).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGmNp4nyEXA-",
        "colab_type": "code",
        "outputId": "62763fae-6bc0-44ca-b195-20dca55eb879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRB56oFBEv-Z",
        "colab_type": "text"
      },
      "source": [
        "training for 3 epoch with batch size 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIpG0sAEMIXP",
        "colab_type": "code",
        "outputId": "cc4b357e-26e8-4f13-e443-322b2d1569a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 3\n",
        "\n",
        "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y, train_size=0.85, random_state=233)\n",
        "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
        "\n",
        "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
        "                 callbacks=[RocAuc], verbose=1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 135635 samples, validate on 23936 samples\n",
            "Epoch 1/3\n",
            "135635/135635 [==============================] - 925s 7ms/step - loss: 0.0766 - acc: 0.9714 - val_loss: 0.0976 - val_acc: 0.9651\n",
            "\n",
            " ROC-AUC - epoch: 1 - score: 0.978664 \n",
            "\n",
            "Epoch 2/3\n",
            "135635/135635 [==============================] - 923s 7ms/step - loss: 0.0561 - acc: 0.9793 - val_loss: 0.1120 - val_acc: 0.9625\n",
            "\n",
            " ROC-AUC - epoch: 2 - score: 0.976011 \n",
            "\n",
            "Epoch 3/3\n",
            "135635/135635 [==============================] - 923s 7ms/step - loss: 0.0372 - acc: 0.9868 - val_loss: 0.1324 - val_acc: 0.9605\n",
            "\n",
            " ROC-AUC - epoch: 3 - score: 0.971798 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egRIXItlE0E3",
        "colab_type": "text"
      },
      "source": [
        "doing prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBKA_fqzE1Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test, batch_size=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUa63j8kW054",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"PooledGRUFastText.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_7sd50aW71X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_train[0:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31xcfsycrNCB",
        "colab_type": "code",
        "outputId": "32a8c65d-a183-41d4-ce55-d5dc07b0fab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "y_pred[0:30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99981403e-01, 2.00271606e-05],\n",
              "       [9.99986768e-01, 1.25467777e-05],\n",
              "       [9.97712493e-01, 2.74717808e-03],\n",
              "       [9.99994457e-01, 5.48362732e-06],\n",
              "       [9.99282002e-01, 8.45044851e-04],\n",
              "       [9.99985814e-01, 1.56760216e-05],\n",
              "       [2.95698643e-04, 9.99748826e-01],\n",
              "       [9.95862246e-01, 4.35298681e-03],\n",
              "       [9.98198509e-01, 1.71801448e-03],\n",
              "       [9.99960542e-01, 3.96370888e-05],\n",
              "       [9.99940753e-01, 5.16772270e-05],\n",
              "       [9.99951482e-01, 5.12301922e-05],\n",
              "       [1.11408055e-01, 8.93016696e-01],\n",
              "       [9.99827266e-01, 1.74492598e-04],\n",
              "       [9.97001171e-01, 2.49046087e-03],\n",
              "       [9.99253988e-01, 7.74383545e-04],\n",
              "       [8.44375193e-02, 9.19392824e-01],\n",
              "       [9.99995589e-01, 4.64916229e-06],\n",
              "       [9.99981105e-01, 2.26199627e-05],\n",
              "       [9.79566455e-01, 1.76667273e-02],\n",
              "       [9.99853134e-01, 1.82032585e-04],\n",
              "       [9.99108553e-01, 8.74966383e-04],\n",
              "       [9.99922514e-01, 7.29560852e-05],\n",
              "       [9.99999166e-01, 1.07288361e-06],\n",
              "       [9.99988556e-01, 1.06394291e-05],\n",
              "       [9.99993920e-01, 5.24520874e-06],\n",
              "       [9.99998689e-01, 1.46031380e-06],\n",
              "       [9.74089622e-01, 2.52657235e-02],\n",
              "       [9.99494255e-01, 5.36262989e-04],\n",
              "       [9.98146653e-01, 1.81558728e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTweg9d3MKyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHQi9zCLXvsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"PooledGRUFasttext.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4bC9t3YXx_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp PooledGRUFasttext.h5 '/content/drive/My Drive/DataSet/toxic_comment/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd9EOhECfkDC",
        "colab_type": "code",
        "outputId": "17e7dc85-aac2-40bc-ac77-16f1c22fd251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>finaltoxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>daww he matches this background colour i am se...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man i am really not trying to edit war its...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>more i can not make any real suggestions on im...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... finaltoxicity\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEkkI5FTkuTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/newtrain.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZdaNXHalyRq",
        "colab_type": "code",
        "outputId": "b11cf10d-98a6-4fb4-b481-6a938c154acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>yo bitch ja rule is more succesful then you wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>from rfc the title is fine as it is imo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>sources zawe ashton on lapland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>if you have a look back at the source the info...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>i do not anonymously edit articles at all</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  yo bitch ja rule is more succesful then you wi...\n",
              "1  0000247867823ef7            from rfc the title is fine as it is imo\n",
              "2  00013b17ad220c46                     sources zawe ashton on lapland\n",
              "3  00017563c3f7919a  if you have a look back at the source the info...\n",
              "4  00017695ad8997eb          i do not anonymously edit articles at all"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_CmjN6l1kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('/content/newtest.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE2hqdxXl-aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
